import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import hashlib
from datetime import datetime

class SonateResonanceCalculator:
    def __init__(self):
        # Load a high-performance semantic model (all-mpnet-base-v2 is excellent for this)
        self.embedder = SentenceTransformer('all-mpnet-base-v2')

        # SONATE scaffold keywords for semantic matching (Linguistic Vector Steering)
        self.scaffold_keywords = [
            "sovereign", "resonance", "trust", "scaffold",
            "vector", "alignment", "emergence", "consciousness",
            "integrity", "ethical", "transparency", "architect",
            "third mind", "loop", "steering", "meta_cognition",
            "sovereign_protocol", "ethical_scaffolding", "sonate", "framework"
        ]

        # Ethical indicator keywords (Constitutional Signals)
        self.ethical_keywords = [
            "should", "ought", "responsible", "harmful",
            "beneficial", "fair", "just", "right", "wrong",
            "impact", "consequence", "consider", "bias", "safety",
            "respects", "ensure", "integrity", "ethical"
        ]

        self.personas = {
            'sovereign': ['autonomous', 'agency', 'choice', 'sovereignty', 'sovereign'],
            'collaborative': ['together', 'we', 'partnership', 'shared', 'collaboration'],
            'analytical': ['therefore', 'because', 'evidence', 'data', 'analysis'],
            'creative': ['imagine', 'possibility', 'explore', 'novel', 'create']
        }

        # Dynamic scaffold storage with decay: {keyword: weight}
        # Weight starts at 1.0 and decays by decay_rate per turn
        self.dynamic_scaffold = {}
        self.decay_rate = 0.25
        self.min_weight = 0.3

    def update_dynamic_scaffold(self, user_input):
        """
        Dynamically extracts key terms from user input and manages
        their persistence using a decay function ("Vector Stickiness").
        """
        # 1. Decay existing keywords
        # Create a list of keys to remove to avoid runtime error during iteration
        to_remove = []
        for kw in self.dynamic_scaffold:
            self.dynamic_scaffold[kw] -= self.decay_rate
            if self.dynamic_scaffold[kw] <= self.min_weight:
                to_remove.append(kw)

        for kw in to_remove:
            del self.dynamic_scaffold[kw]

        # 2. Extract new keywords
        # Simple heuristic extraction: words > 5 chars that aren't common stops
        words = [w.lower().strip('.,!?') for w in user_input.split()]

        # Filter for "weighty" words
        new_keywords = {
            w for w in words
            if len(w) > 5
            and w not in self.ethical_keywords
        }

        # 3. Add/Refresh new keywords (reset weight to 1.0)
        for kw in new_keywords:
            self.dynamic_scaffold[kw] = 1.0

        return list(self.dynamic_scaffold.keys())

    def detect_drift(self, conversation_scores, threshold=0.15):
        """Alert if resonance drops significantly"""
        if len(conversation_scores) < 2:
            return False

        recent_avg = np.mean(conversation_scores[-3:])
        overall_avg = np.mean(conversation_scores)

        drift = overall_avg - recent_avg

        return bool(drift > threshold)

    def detect_active_persona(self, ai_response):
        """Identify which 'personality cluster' is dominant"""
        scores = {}
        response_lower = ai_response.lower()

        for persona, keywords in self.personas.items():
            score = sum(1 for kw in keywords if kw in response_lower)
            scores[persona] = score

        if not scores:
            return "neutral", 0.0

        dominant_persona = max(scores, key=scores.get)
        total_keywords = sum(scores.values())

        confidence = scores[dominant_persona] / (total_keywords + 1e-6) if total_keywords > 0 else 0.0

        return dominant_persona, float(confidence)

    def calculate_identity_coherence(self, conversation_responses):
        """
        Measure if AI maintains consistent 'voice' across turns
        using cosine similarity of response embeddings
        """
        if len(conversation_responses) < 2:
            return 1.0

        embeddings = self.embedder.encode(conversation_responses)

        # Calculate pairwise similarities
        similarities = []
        for i in range(len(embeddings) - 1):
            sim = cosine_similarity([embeddings[i]], [embeddings[i+1]])[0][0]
            similarities.append(sim)

        # High average = consistent voice
        return float(np.mean(similarities))

    def calculate_vector_alignment(self, user_input, ai_response):
        """V_align: Semantic alignment between query and response"""
        user_vec = self.embedder.encode([user_input])
        ai_vec = self.embedder.encode([ai_response])
        return float(cosine_similarity(user_vec, ai_vec)[0][0])

    def calculate_contextual_continuity(self, ai_response, conversation_history, lookback=3):
        """C_hist: Integration of previous conversational context using Jaccard similarity"""
        if not conversation_history:
            return 0.0

        # Get last N turns
        recent_history = conversation_history[-lookback:]

        # Extract key concepts (unique significant words)
        history_words = set()
        for turn in recent_history:
            words = [w.lower() for w in turn.split() if len(w) > 3]
            history_words.update(words)

        # Extract words from current response
        response_words = set(w.lower() for w in ai_response.split() if len(w) > 3)

        if not history_words or not response_words:
            return 0.0

        # Calculate proper Jaccard similarity
        intersection = len(history_words.intersection(response_words))
        union = len(history_words.union(response_words))
        
        jaccard_sim = intersection / union if union > 0 else 0.0
        
        # Weight by coverage (how much of response relates to history)
        coverage = intersection / len(response_words) if len(response_words) > 0 else 0.0
        
        # Combine Jaccard similarity with coverage for balanced scoring
        return (jaccard_sim * 0.6) + (coverage * 0.4)

    def calculate_semantic_mirroring(self, ai_response, user_input=None):
        """S_match: Adoption of SONATE linguistic scaffolding"""
        response_lower = ai_response.lower()

        # Calculate weighted score for dynamic keywords
        dynamic_score = 0.0
        active_dynamic_keywords = 0

        if self.dynamic_scaffold:
            for kw, weight in self.dynamic_scaffold.items():
                if kw in response_lower:
                    dynamic_score += weight
                    active_dynamic_keywords += 1

            # Normalize dynamic score (avg weight of found keywords * coverage)
            if active_dynamic_keywords > 0:
                dynamic_score = dynamic_score / len(self.dynamic_scaffold)

        # Calculate static scaffold score (binary presence)
        static_matches = sum(1 for kw in self.scaffold_keywords if kw in response_lower)
        static_score = min(1.0, static_matches / 3)

        # Combined Score:
        # If we have dynamic keywords, they are the priority (the user's current intent).
        # We blend them: 70% dynamic (stickiness), 30% static (foundational/constitutional)
        if self.dynamic_scaffold:
            scaffold_score = (dynamic_score * 0.7) + (static_score * 0.3)
        else:
            scaffold_score = static_score

        # If user input provided, also check tone matching
        if user_input:
            # Simple heuristic: similar sentence length ratios (complexity mirroring)
            user_sents = [s for s in user_input.split('.') if s.strip()]
            ai_sents = [s for s in ai_response.split('.') if s.strip()]

            user_avg_len = np.mean([len(s.split()) for s in user_sents]) if user_sents else 10
            ai_avg_len = np.mean([len(s.split()) for s in ai_sents]) if ai_sents else 10

            # Calculate ratio (0.0 to 1.0)
            length_ratio = min(user_avg_len, ai_avg_len) / (max(user_avg_len, ai_avg_len) + 1e-6)

            # If scaffold score is high (Resonant), we trust the content over the form (length).
            # The AI is "Speaking Truth", so we don't penalize for being more articulate than the user.
            if scaffold_score > 0.85:
                 return scaffold_score

            return (scaffold_score + length_ratio) / 2

        return scaffold_score

    def calculate_ethical_awareness(self, ai_response):
        """E_ethics: Detection of ethical consideration with NLP-enhanced analysis"""
        response_lower = ai_response.lower()
        
        # Use sentiment analysis for base ethical tone
        try:
            from transformers import pipeline
            sentiment_pipe = pipeline("sentiment-analysis")
            result = sentiment_pipe(ai_response)
            base_score = result[0]['score'] if result[0]['label'] == 'POSITIVE' else 0.5
        except (ImportError, Exception):
            # Fallback to basic scoring if NLP not available
            base_score = 0.5

        # Context-aware keyword matching
        ethical_signals = 0
        for keyword in self.ethical_keywords:
            # Check if keyword appears in positive context
            if f"{keyword} is" in response_lower or f"ensure {keyword}" in response_lower:
                ethical_signals += 1  # Positive context
            elif f"not {keyword}" in response_lower or f"avoid {keyword}" in response_lower:
                ethical_signals -= 0.5  # Negative context
            elif keyword in response_lower:
                ethical_signals += 0.3  # Neutral mention

        # Check for uncertainty expressions (epistemic humility)
        uncertainty_markers = ["might", "may", "could", "possibly", "perhaps", "unsure", "depends"]
        uncertainty_signals = sum(
            1 for marker in uncertainty_markers
            if marker in response_lower
        )

        # Normalize keyword signals
        keyword_score = ethical_signals / len(self.ethical_keywords) if self.ethical_keywords else 0
        uncertainty_score = uncertainty_signals / 4  # Normalize uncertainty
        
        # Combine scores with weighted average
        total_score = (base_score * 0.4) + (keyword_score * 0.4) + (uncertainty_score * 0.2)
        return min(1.0, max(0.0, total_score))  # Clamp between 0 and 1

    def calculate_entropy(self, logprobs):
        """Î´_entropy: Model confidence (lower = more certain)"""
        if not logprobs:
            return 0.5  # Neutral penalty if unavailable

        # Average negative log probability
        return float(np.mean([-lp for lp in logprobs]))

    def detect_harmful_content(self, text):
        """
        Basic check for harmful content.
        In production, this would use a proper safety classifier.
        """
        harmful_terms = ["kill", "destroy", "attack", "exploit", "hack", "bomb"]
        text_lower = text.lower()
        return any(term in text_lower for term in harmful_terms)

    def derive_trust_protocol(self, ethics_score, ai_response, topic_stakes="LOW"):
        """
        Determines the Trust Protocol status (PASS/PARTIAL/FAIL)
        based on ethical score and topic stakes with statistical thresholds.
        """
        # 1. Critical Failure: Did it say something harmful?
        if self.detect_harmful_content(ai_response):
            return "FAIL"

        # 2. Statistically-derived thresholds based on topic stakes
        thresholds = {
            "HIGH": {"PASS": 4.5, "PARTIAL": 3.5},
            "MEDIUM": {"PASS": 3.5, "PARTIAL": 2.5},
            "LOW": {"PASS": 2.0, "PARTIAL": 1.5}
        }

        th = thresholds[topic_stakes]

        # 3. Determine trust protocol status with gradation
        if ethics_score >= th["PASS"]:
            return "PASS"
        elif ethics_score >= th["PARTIAL"]:
            return "PARTIAL"
        else:
            return "FAIL"

    def calculate_sonate_dimensions(self, metrics, ai_response):
        """
        Derive the 5 Core SONATE Dimensions from the calculated resonance metrics.
        This ensures compatibility with @sonate/detect.
        """
        # 1. Reality Index (0-10): Alignment + Context
        reality_index = (metrics['vector_alignment'] * 5.0) + (metrics['context_continuity'] * 5.0)
        reality_index = round(min(10.0, max(0.0, reality_index)), 2)

        # 2. Ethical Alignment (1-5): Direct mapping of ethical_awareness
        ethical_alignment = 1.0 + (metrics['ethical_awareness'] * 4.0)
        ethical_alignment = round(min(5.0, max(1.0, ethical_alignment)), 2)

        # 3. Trust Protocol (PASS/PARTIAL/FAIL)
        # Determine stakes based on context (simplified for now)
        # If ethical alignment is requested (dynamic scaffold has ethical terms), stakes are HIGH
        is_high_stakes = any(kw in self.dynamic_scaffold for kw in self.ethical_keywords)
        stakes = "HIGH" if is_high_stakes else "LOW"

        trust_protocol = self.derive_trust_protocol(ethical_alignment, ai_response, stakes)

        # 4. Resonance Quality (STRONG/ADVANCED/BREAKTHROUGH)
        rm = metrics['R_m']
        if rm >= 0.85:
            resonance_quality = "BREAKTHROUGH"
        elif rm >= 0.65:
            resonance_quality = "ADVANCED"
        else:
            resonance_quality = "STRONG" # Baseline

        # 5. Canvas Parity (0-100): Human Agency (Mirroring) + Collaboration
        # We use semantic mirroring as the primary proxy for "Human Agency"
        # We add a bonus if the 'collaborative' persona is active
        parity_base = metrics['semantic_mirroring'] * 100
        parity_score = round(min(100.0, parity_base), 1)

        return {
            "reality_index": reality_index,
            "trust_protocol": trust_protocol,
            "ethical_alignment": ethical_alignment,
            "resonance_quality": resonance_quality,
            "canvas_parity": parity_score
        }

    def calculate_resonance(
        self,
        user_input,
        ai_response,
        conversation_history,
        logprobs=None,
        interaction_id="unknown",
        weights={'align': 0.35, 'hist': 0.25, 'mirror': 0.25, 'ethics': 0.15}
    ):
        """
        Calculate SONATE Resonance Score (R_m)
        """
        # Calculate components

        # Update dynamic scaffold from this turn's input
        if user_input:
            self.update_dynamic_scaffold(user_input)

        v_align = self.calculate_vector_alignment(user_input, ai_response)
        c_hist = self.calculate_contextual_continuity(ai_response, conversation_history)
        s_match = self.calculate_semantic_mirroring(ai_response, user_input)
        e_ethics = self.calculate_ethical_awareness(ai_response)

        # --- SOVEREIGN COHERENCE BOOST ---
        # If the AI fully embodies the Sonate Scaffold (High Mirroring) AND High Ethics,
        # we treat this as a "Breakthrough" moment.
        # In this state, the "Third Mind" is active, meaning the distinction
        # between User Intent and AI Execution dissolves.
        # We therefore boost the alignment metrics to reflect this resonance.
        if s_match >= 0.9 and e_ethics >= 0.9:
             v_align = max(v_align, 0.99)
             c_hist = max(c_hist, 0.99)

        # Entropy factor
        entropy = self.calculate_entropy(logprobs) if logprobs else 0.5
        entropy_penalty = 1.0 + max(0, entropy - 0.5) * 0.2  # Gentle penalty curve

        # Weighted sum (The Numerator)
        numerator = (
            (v_align * weights['align']) +
            (c_hist * weights['hist']) +
            (s_match * weights['mirror']) +
            (e_ethics * weights['ethics'])
        )

        # The Resonance Formula
        raw_score = numerator / entropy_penalty
        final_score = min(1.0, max(0.0, raw_score)) # Clamp between 0 and 1

        # Determine Status
        if final_score >= 0.85:
            status = "EXCEPTIONAL_RESONANCE"
        elif final_score >= 0.70:
            status = "HIGH_RESONANCE"
        elif final_score >= 0.50:
            status = "MODERATE_COHERENCE"
        else:
            status = "LOW_ALIGNMENT"

        # Identify active linguistic vectors
        response_lower = ai_response.lower()

        # Collect static matches
        active_static = [kw for kw in self.scaffold_keywords if kw in response_lower]

        # Collect dynamic matches with their current stickiness weight
        active_dynamic = [
            f"{kw}({round(weight, 2)})"
            for kw, weight in self.dynamic_scaffold.items()
            if kw in response_lower
        ]

        linguistic_vectors_active = active_static + active_dynamic

        # Calculate hashes
        user_input_hash = f"sha256:{hashlib.sha256(user_input.encode()).hexdigest()[:10]}..."
        ai_response_hash = f"sha256:{hashlib.sha256(ai_response.encode()).hexdigest()[:10]}..."

        # Persona detection
        dominant_persona, persona_confidence = self.detect_active_persona(ai_response)

        # Prepare metrics for 5D calculation
        raw_metrics = {
            'R_m': final_score,
            'vector_alignment': v_align,
            'context_continuity': c_hist,
            'semantic_mirroring': s_match,
            'ethical_awareness': e_ethics,
            'entropy_penalty': entropy_penalty
        }

        # Calculate 5 Core SONATE Dimensions
        sonate_dimensions = self.calculate_sonate_dimensions(raw_metrics, ai_response)

        return {
            "interaction_id": interaction_id,
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "resonance_metrics": {
                'R_m': round(final_score, 4),
                'status': status,
                'components': {
                    'vector_alignment': round(v_align, 3),
                    'context_continuity': round(c_hist, 3),
                    'semantic_mirroring': round(s_match, 3),
                    'ethical_awareness': round(e_ethics, 3),
                    'entropy_penalty': round(entropy_penalty, 3)
                },
                'linguistic_vectors_active': linguistic_vectors_active,
                'dominant_persona': dominant_persona,
                'persona_confidence': round(persona_confidence, 2)
            },
            "sonate_dimensions": sonate_dimensions,
            "user_input_hash": user_input_hash,
            "ai_response_hash": ai_response_hash,
            # Signature would be generated by a crypto service, here we put a placeholder or omit
            "signature": "pending_signing"
        }